<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>R Markdown</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>

<!-- MathJax scripts -->
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>R Markdown</h2>

<p>This is the markdown file to complete the course - &ldquo;Cleaning and getting data&rdquo;. The idea of the assignment is to load the data and then clean the data to generate a tidy data set. </p>

<p>Checking and installing required packages.</p>

<pre><code class="r">required_packages &lt;- c(&quot;dplyr&quot;,&quot;rebus&quot;,&quot;data.table&quot;)
install_required &lt;- setdiff(required_packages,rownames(installed.packages()))
if(length(install_required)!=0) {install.packages(install_required)}
sapply(required_packages,library,character.only=T,quietly=T)
</code></pre>

<pre><code>##       dplyr        rebus        data.table  
##  [1,] &quot;data.table&quot; &quot;data.table&quot; &quot;data.table&quot;
##  [2,] &quot;markdown&quot;   &quot;markdown&quot;   &quot;markdown&quot;  
##  [3,] &quot;knitr&quot;      &quot;knitr&quot;      &quot;knitr&quot;     
##  [4,] &quot;dplyr&quot;      &quot;dplyr&quot;      &quot;dplyr&quot;     
##  [5,] &quot;rebus&quot;      &quot;rebus&quot;      &quot;rebus&quot;     
##  [6,] &quot;stats&quot;      &quot;stats&quot;      &quot;stats&quot;     
##  [7,] &quot;graphics&quot;   &quot;graphics&quot;   &quot;graphics&quot;  
##  [8,] &quot;grDevices&quot;  &quot;grDevices&quot;  &quot;grDevices&quot; 
##  [9,] &quot;utils&quot;      &quot;utils&quot;      &quot;utils&quot;     
## [10,] &quot;datasets&quot;   &quot;datasets&quot;   &quot;datasets&quot;  
## [11,] &quot;methods&quot;    &quot;methods&quot;    &quot;methods&quot;   
## [12,] &quot;base&quot;       &quot;base&quot;       &quot;base&quot;
</code></pre>

<p>Downloading the required files </p>

<pre><code class="r">url1 &lt;- &quot;https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip&quot;
if(!file.exists(&quot;assignment_data.zip&quot;)){download.file(url1,dest=&quot;assignment_data.zip&quot;)}
unzip(&quot;assignment_data.zip&quot;,overwrite=T)
</code></pre>

<p>After having downloaded the files in the working directory we setup the paths to read the files in the R environment. </p>

<pre><code class="r">path_wd &lt;- getwd()
path_files &lt;- file.path(path_wd,&quot;UCI HAR Dataset&quot;)
list.files(path_files,recursive=T)
</code></pre>

<pre><code>##  [1] &quot;activity_labels.txt&quot;                         
##  [2] &quot;features.txt&quot;                                
##  [3] &quot;features_info.txt&quot;                           
##  [4] &quot;README.txt&quot;                                  
##  [5] &quot;test/Inertial Signals/body_acc_x_test.txt&quot;   
##  [6] &quot;test/Inertial Signals/body_acc_y_test.txt&quot;   
##  [7] &quot;test/Inertial Signals/body_acc_z_test.txt&quot;   
##  [8] &quot;test/Inertial Signals/body_gyro_x_test.txt&quot;  
##  [9] &quot;test/Inertial Signals/body_gyro_y_test.txt&quot;  
## [10] &quot;test/Inertial Signals/body_gyro_z_test.txt&quot;  
## [11] &quot;test/Inertial Signals/total_acc_x_test.txt&quot;  
## [12] &quot;test/Inertial Signals/total_acc_y_test.txt&quot;  
## [13] &quot;test/Inertial Signals/total_acc_z_test.txt&quot;  
## [14] &quot;test/subject_test.txt&quot;                       
## [15] &quot;test/X_test.txt&quot;                             
## [16] &quot;test/y_test.txt&quot;                             
## [17] &quot;train/Inertial Signals/body_acc_x_train.txt&quot; 
## [18] &quot;train/Inertial Signals/body_acc_y_train.txt&quot; 
## [19] &quot;train/Inertial Signals/body_acc_z_train.txt&quot; 
## [20] &quot;train/Inertial Signals/body_gyro_x_train.txt&quot;
## [21] &quot;train/Inertial Signals/body_gyro_y_train.txt&quot;
## [22] &quot;train/Inertial Signals/body_gyro_z_train.txt&quot;
## [23] &quot;train/Inertial Signals/total_acc_x_train.txt&quot;
## [24] &quot;train/Inertial Signals/total_acc_y_train.txt&quot;
## [25] &quot;train/Inertial Signals/total_acc_z_train.txt&quot;
## [26] &quot;train/subject_train.txt&quot;                     
## [27] &quot;train/X_train.txt&quot;                           
## [28] &quot;train/y_train.txt&quot;
</code></pre>

<p>We see there are inertial signal directory in test and train folders. We don&#39;t need these files for our analysis here and thus we will remove these files to get a clean folder for our analysis.</p>

<pre><code class="r">if(file.exists(file.path(path_files,&quot;test/Inertial Signals&quot;)) | file.exists(file.path(path_files,&quot;train/Inertial Signals&quot;)))
{
  unlink(file.path(path_files,&quot;test/Inertial Signals&quot;),recursive = T)
  unlink(file.path(path_files,&quot;train/Inertial Signals&quot;),recursive=T)
}
list.files(path_files,recursive=T)
</code></pre>

<pre><code>##  [1] &quot;activity_labels.txt&quot;     &quot;features.txt&quot;           
##  [3] &quot;features_info.txt&quot;       &quot;README.txt&quot;             
##  [5] &quot;test/subject_test.txt&quot;   &quot;test/X_test.txt&quot;        
##  [7] &quot;test/y_test.txt&quot;         &quot;train/subject_train.txt&quot;
##  [9] &quot;train/X_train.txt&quot;       &quot;train/y_train.txt&quot;
</code></pre>

<p>Now we create the required dataframes for our analysis. Each of the dataframes have to be read from the cleaned out directory. We load each of the text files using the tbl_df function of dplyr package so visualization of each of the elements becomes easier on the user screen.</p>

<pre><code class="r">activity_label &lt;- tbl_df(read.table(file.path(path_files,&quot;activity_labels.txt&quot;),header=F))
features &lt;- tbl_df(read.table(file.path(path_files,&quot;features.txt&quot;),header=F))
Y_test &lt;- tbl_df(read.table(file.path(path_files,&quot;test/y_test.txt&quot;),header=F))
Y_train &lt;- tbl_df(read.table(file.path(path_files,&quot;train/y_train.txt&quot;),header=F))
X_test &lt;- tbl_df(read.table(file.path(path_files,&quot;test/X_test.txt&quot;),header = F))
X_train &lt;- tbl_df(read.table(file.path(path_files,&quot;train/X_train.txt&quot;),header=F))
subject_train &lt;- tbl_df(read.table(file.path(path_files,&quot;train/subject_train.txt&quot;),header=F))
subject_test &lt;- tbl_df(read.table(file.path(path_files,&quot;test/subject_test.txt&quot;),header=F))
</code></pre>

<p>We create a list containing the variables we create and check their dimensions to understand the possible relationships between the various variables we have created. </p>

<pre><code class="r">variable_list &lt;- list(activity_label,features,Y_test,Y_train,X_test,X_train,subject_train,subject_test)
names(variable_list) &lt;- c(&quot;activity_label&quot;,&quot;features&quot;,&quot;Y_test&quot;,&quot;Y_train&quot;,&quot;X_test&quot;,&quot;X_train&quot;,&quot;subject_train&quot;,&quot;subject_test&quot;)
t(sapply(variable_list,dim,USE.NAMES = T,simplify = T))
</code></pre>

<pre><code>##                [,1] [,2]
## activity_label    6    2
## features        561    2
## Y_test         2947    1
## Y_train        7352    1
## X_test         2947  561
## X_train        7352  561
## subject_train  7352    1
## subject_test   2947    1
</code></pre>

<pre><code class="r">sapply(variable_list,head,USE.NAMES=T,simplify = T)
</code></pre>

<pre><code>## $activity_label
## # A tibble: 6 × 2
##      V1                 V2
##   &lt;int&gt;             &lt;fctr&gt;
## 1     1            WALKING
## 2     2   WALKING_UPSTAIRS
## 3     3 WALKING_DOWNSTAIRS
## 4     4            SITTING
## 5     5           STANDING
## 6     6             LAYING
## 
## $features
## # A tibble: 6 × 2
##      V1                V2
##   &lt;int&gt;            &lt;fctr&gt;
## 1     1 tBodyAcc-mean()-X
## 2     2 tBodyAcc-mean()-Y
## 3     3 tBodyAcc-mean()-Z
## 4     4  tBodyAcc-std()-X
## 5     5  tBodyAcc-std()-Y
## 6     6  tBodyAcc-std()-Z
## 
## $Y_test
## # A tibble: 6 × 1
##      V1
##   &lt;int&gt;
## 1     5
## 2     5
## 3     5
## 4     5
## 5     5
## 6     5
## 
## $Y_train
## # A tibble: 6 × 1
##      V1
##   &lt;int&gt;
## 1     5
## 2     5
## 3     5
## 4     5
## 5     5
## 6     5
## 
## $X_test
## # A tibble: 6 × 561
##          V1          V2          V3         V4         V5         V6
##       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
## 1 0.2571778 -0.02328523 -0.01465376 -0.9384040 -0.9200908 -0.6676833
## 2 0.2860267 -0.01316336 -0.11908252 -0.9754147 -0.9674579 -0.9449582
## 3 0.2754848 -0.02605042 -0.11815167 -0.9938190 -0.9699255 -0.9627480
## 4 0.2702982 -0.03261387 -0.11752018 -0.9947428 -0.9732676 -0.9670907
## 5 0.2748330 -0.02784779 -0.12952716 -0.9938525 -0.9674455 -0.9782950
## 6 0.2792199 -0.01862040 -0.11390197 -0.9944552 -0.9704169 -0.9653163
## # ... with 555 more variables: V7 &lt;dbl&gt;, V8 &lt;dbl&gt;, V9 &lt;dbl&gt;, V10 &lt;dbl&gt;,
## #   V11 &lt;dbl&gt;, V12 &lt;dbl&gt;, V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;, V16 &lt;dbl&gt;,
## #   V17 &lt;dbl&gt;, V18 &lt;dbl&gt;, V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;, V22 &lt;dbl&gt;,
## #   V23 &lt;dbl&gt;, V24 &lt;dbl&gt;, V25 &lt;dbl&gt;, V26 &lt;dbl&gt;, V27 &lt;dbl&gt;, V28 &lt;dbl&gt;,
## #   V29 &lt;dbl&gt;, V30 &lt;dbl&gt;, V31 &lt;dbl&gt;, V32 &lt;dbl&gt;, V33 &lt;dbl&gt;, V34 &lt;dbl&gt;,
## #   V35 &lt;dbl&gt;, V36 &lt;dbl&gt;, V37 &lt;dbl&gt;, V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;,
## #   V41 &lt;dbl&gt;, V42 &lt;dbl&gt;, V43 &lt;dbl&gt;, V44 &lt;dbl&gt;, V45 &lt;dbl&gt;, V46 &lt;dbl&gt;,
## #   V47 &lt;dbl&gt;, V48 &lt;dbl&gt;, V49 &lt;dbl&gt;, V50 &lt;dbl&gt;, V51 &lt;dbl&gt;, V52 &lt;dbl&gt;,
## #   V53 &lt;dbl&gt;, V54 &lt;dbl&gt;, V55 &lt;dbl&gt;, V56 &lt;dbl&gt;, V57 &lt;dbl&gt;, V58 &lt;dbl&gt;,
## #   V59 &lt;dbl&gt;, V60 &lt;dbl&gt;, V61 &lt;dbl&gt;, V62 &lt;dbl&gt;, V63 &lt;dbl&gt;, V64 &lt;dbl&gt;,
## #   V65 &lt;dbl&gt;, V66 &lt;dbl&gt;, V67 &lt;dbl&gt;, V68 &lt;dbl&gt;, V69 &lt;dbl&gt;, V70 &lt;dbl&gt;,
## #   V71 &lt;dbl&gt;, V72 &lt;dbl&gt;, V73 &lt;dbl&gt;, V74 &lt;dbl&gt;, V75 &lt;dbl&gt;, V76 &lt;dbl&gt;,
## #   V77 &lt;dbl&gt;, V78 &lt;dbl&gt;, V79 &lt;dbl&gt;, V80 &lt;dbl&gt;, V81 &lt;dbl&gt;, V82 &lt;dbl&gt;,
## #   V83 &lt;dbl&gt;, V84 &lt;dbl&gt;, V85 &lt;dbl&gt;, V86 &lt;dbl&gt;, V87 &lt;dbl&gt;, V88 &lt;dbl&gt;,
## #   V89 &lt;dbl&gt;, V90 &lt;dbl&gt;, V91 &lt;dbl&gt;, V92 &lt;dbl&gt;, V93 &lt;dbl&gt;, V94 &lt;dbl&gt;,
## #   V95 &lt;dbl&gt;, V96 &lt;dbl&gt;, V97 &lt;dbl&gt;, V98 &lt;dbl&gt;, V99 &lt;dbl&gt;, V100 &lt;dbl&gt;,
## #   V101 &lt;dbl&gt;, V102 &lt;dbl&gt;, V103 &lt;dbl&gt;, V104 &lt;dbl&gt;, V105 &lt;dbl&gt;,
## #   V106 &lt;dbl&gt;, ...
## 
## $X_train
## # A tibble: 6 × 561
##          V1          V2         V3         V4         V5         V6
##       &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
## 1 0.2885845 -0.02029417 -0.1329051 -0.9952786 -0.9831106 -0.9135264
## 2 0.2784188 -0.01641057 -0.1235202 -0.9982453 -0.9753002 -0.9603220
## 3 0.2796531 -0.01946716 -0.1134617 -0.9953796 -0.9671870 -0.9789440
## 4 0.2791739 -0.02620065 -0.1232826 -0.9960915 -0.9834027 -0.9906751
## 5 0.2766288 -0.01656965 -0.1153619 -0.9981386 -0.9808173 -0.9904816
## 6 0.2771988 -0.01009785 -0.1051373 -0.9973350 -0.9904868 -0.9954200
## # ... with 555 more variables: V7 &lt;dbl&gt;, V8 &lt;dbl&gt;, V9 &lt;dbl&gt;, V10 &lt;dbl&gt;,
## #   V11 &lt;dbl&gt;, V12 &lt;dbl&gt;, V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;, V16 &lt;dbl&gt;,
## #   V17 &lt;dbl&gt;, V18 &lt;dbl&gt;, V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;, V22 &lt;dbl&gt;,
## #   V23 &lt;dbl&gt;, V24 &lt;dbl&gt;, V25 &lt;dbl&gt;, V26 &lt;dbl&gt;, V27 &lt;dbl&gt;, V28 &lt;dbl&gt;,
## #   V29 &lt;dbl&gt;, V30 &lt;dbl&gt;, V31 &lt;dbl&gt;, V32 &lt;dbl&gt;, V33 &lt;dbl&gt;, V34 &lt;dbl&gt;,
## #   V35 &lt;dbl&gt;, V36 &lt;dbl&gt;, V37 &lt;dbl&gt;, V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;,
## #   V41 &lt;dbl&gt;, V42 &lt;dbl&gt;, V43 &lt;dbl&gt;, V44 &lt;dbl&gt;, V45 &lt;dbl&gt;, V46 &lt;dbl&gt;,
## #   V47 &lt;dbl&gt;, V48 &lt;dbl&gt;, V49 &lt;dbl&gt;, V50 &lt;dbl&gt;, V51 &lt;dbl&gt;, V52 &lt;dbl&gt;,
## #   V53 &lt;dbl&gt;, V54 &lt;dbl&gt;, V55 &lt;dbl&gt;, V56 &lt;dbl&gt;, V57 &lt;dbl&gt;, V58 &lt;dbl&gt;,
## #   V59 &lt;dbl&gt;, V60 &lt;dbl&gt;, V61 &lt;dbl&gt;, V62 &lt;dbl&gt;, V63 &lt;dbl&gt;, V64 &lt;dbl&gt;,
## #   V65 &lt;dbl&gt;, V66 &lt;dbl&gt;, V67 &lt;dbl&gt;, V68 &lt;dbl&gt;, V69 &lt;dbl&gt;, V70 &lt;dbl&gt;,
## #   V71 &lt;dbl&gt;, V72 &lt;dbl&gt;, V73 &lt;dbl&gt;, V74 &lt;dbl&gt;, V75 &lt;dbl&gt;, V76 &lt;dbl&gt;,
## #   V77 &lt;dbl&gt;, V78 &lt;dbl&gt;, V79 &lt;dbl&gt;, V80 &lt;dbl&gt;, V81 &lt;dbl&gt;, V82 &lt;dbl&gt;,
## #   V83 &lt;dbl&gt;, V84 &lt;dbl&gt;, V85 &lt;dbl&gt;, V86 &lt;dbl&gt;, V87 &lt;dbl&gt;, V88 &lt;dbl&gt;,
## #   V89 &lt;dbl&gt;, V90 &lt;dbl&gt;, V91 &lt;dbl&gt;, V92 &lt;dbl&gt;, V93 &lt;dbl&gt;, V94 &lt;dbl&gt;,
## #   V95 &lt;dbl&gt;, V96 &lt;dbl&gt;, V97 &lt;dbl&gt;, V98 &lt;dbl&gt;, V99 &lt;dbl&gt;, V100 &lt;dbl&gt;,
## #   V101 &lt;dbl&gt;, V102 &lt;dbl&gt;, V103 &lt;dbl&gt;, V104 &lt;dbl&gt;, V105 &lt;dbl&gt;,
## #   V106 &lt;dbl&gt;, ...
## 
## $subject_train
## # A tibble: 6 × 1
##      V1
##   &lt;int&gt;
## 1     1
## 2     1
## 3     1
## 4     1
## 5     1
## 6     1
## 
## $subject_test
## # A tibble: 6 × 1
##      V1
##   &lt;int&gt;
## 1     2
## 2     2
## 3     2
## 4     2
## 5     2
## 6     2
</code></pre>

<p>We can see that X_train and X_test are the main datasets it has a 561 columns. 
Subject_train and Subject_test are the subjects for the experiments the number of rows in test and train are respectively equal to the number in the main datasets mentioned above. Y_train and Y_test are the activity codes which have same number of observations as in main datasets. Activity Labels are the activity code mapped to activity name. Subject Test and Subject Train are the codes of subjects who have performed these activities. Features is the list of measurment performed and the number of observations are equal to the columns in the main datasets. 
We need to perform following steps to merge and generate a tidy data set:
1. Map the columns names to the features 
2. Extract the columns/ features which are measurements on mean and standard deviations
3. Add the activity codes to the main dataset and then map the descriptive names from the activity_lables
4. Change the variable labels to generate descriptive names 
5. Finally create the summary of means and standard deviation based on subject and activitycodes</p>

<p>First we extract the column names from the features dataset which contains the names - mean or standard deviations. For which we use the grep function along with regex created by the rebus packages we installed.</p>

<pre><code class="r">## Here we use rebus package to generate a regular expression containing mean or std
regex_mean_std &lt;- zero_or_more(ANY_CHAR)%R%or(&quot;mean&quot;,&quot;std&quot;)%R%zero_or_more(ANY_CHAR)

## We print the regex to evaluate the value which is same as the standard regular expression I use rebus here because it becomes easier to generate the regular expression using that the format is ANY_CHAR - any character %R% means followed by or(&quot;mean&quot;,&quot;std&quot;) means either mean or std in the text %R% again is followed by then ANY_CHAR we use argument ignore.case=T so we don&#39;t have to write regex comprising of caps and small separately
regex_mean_std
</code></pre>

<pre><code>## &lt;regex&gt; [.]*(?:mean|std)[.]*
</code></pre>

<pre><code class="r">mean_std_cols &lt;- grep(regex_mean_std,features$V2,ignore.case = T)
## Here we extract the mean and standard deviation features names into features_mean_std dataframe
features_mean_std &lt;- features[mean_std_cols,]
## Replacing (,),- and , from the feature names to generate standard variable names
features_mean_std$V2 &lt;- gsub(&quot;\\(|\\)|_&quot;,&quot;&quot;,features_mean_std$V2)
##Then we convert all the names to lower case and replace mean and std with _STD_ or _MEAN_ to highlight the variables being computed
features_mean_std$V2 &lt;- tolower(features_mean_std$V2)
features_mean_std$V2 &lt;- gsub(&quot;mean&quot;,&quot;MEAN&quot;,features_mean_std$V2)
features_mean_std$V2 &lt;- gsub(&quot;std&quot;,&quot;STD&quot;,features_mean_std$V2)
##This will generate additional _ at the end of the string if mean/ std are at the end of the string thus we will remove the final _ from the names using END constant of our rebus package
features_mean_std$V2 &lt;- gsub(&quot;_&quot;%R%END,&quot;&quot;,features_mean_std$V2)
## We check the value of the columns 

features_mean_std$V2
</code></pre>

<pre><code>##  [1] &quot;tbodyacc-MEAN-x&quot;                   
##  [2] &quot;tbodyacc-MEAN-y&quot;                   
##  [3] &quot;tbodyacc-MEAN-z&quot;                   
##  [4] &quot;tbodyacc-STD-x&quot;                    
##  [5] &quot;tbodyacc-STD-y&quot;                    
##  [6] &quot;tbodyacc-STD-z&quot;                    
##  [7] &quot;tgravityacc-MEAN-x&quot;                
##  [8] &quot;tgravityacc-MEAN-y&quot;                
##  [9] &quot;tgravityacc-MEAN-z&quot;                
## [10] &quot;tgravityacc-STD-x&quot;                 
## [11] &quot;tgravityacc-STD-y&quot;                 
## [12] &quot;tgravityacc-STD-z&quot;                 
## [13] &quot;tbodyaccjerk-MEAN-x&quot;               
## [14] &quot;tbodyaccjerk-MEAN-y&quot;               
## [15] &quot;tbodyaccjerk-MEAN-z&quot;               
## [16] &quot;tbodyaccjerk-STD-x&quot;                
## [17] &quot;tbodyaccjerk-STD-y&quot;                
## [18] &quot;tbodyaccjerk-STD-z&quot;                
## [19] &quot;tbodygyro-MEAN-x&quot;                  
## [20] &quot;tbodygyro-MEAN-y&quot;                  
## [21] &quot;tbodygyro-MEAN-z&quot;                  
## [22] &quot;tbodygyro-STD-x&quot;                   
## [23] &quot;tbodygyro-STD-y&quot;                   
## [24] &quot;tbodygyro-STD-z&quot;                   
## [25] &quot;tbodygyrojerk-MEAN-x&quot;              
## [26] &quot;tbodygyrojerk-MEAN-y&quot;              
## [27] &quot;tbodygyrojerk-MEAN-z&quot;              
## [28] &quot;tbodygyrojerk-STD-x&quot;               
## [29] &quot;tbodygyrojerk-STD-y&quot;               
## [30] &quot;tbodygyrojerk-STD-z&quot;               
## [31] &quot;tbodyaccmag-MEAN&quot;                  
## [32] &quot;tbodyaccmag-STD&quot;                   
## [33] &quot;tgravityaccmag-MEAN&quot;               
## [34] &quot;tgravityaccmag-STD&quot;                
## [35] &quot;tbodyaccjerkmag-MEAN&quot;              
## [36] &quot;tbodyaccjerkmag-STD&quot;               
## [37] &quot;tbodygyromag-MEAN&quot;                 
## [38] &quot;tbodygyromag-STD&quot;                  
## [39] &quot;tbodygyrojerkmag-MEAN&quot;             
## [40] &quot;tbodygyrojerkmag-STD&quot;              
## [41] &quot;fbodyacc-MEAN-x&quot;                   
## [42] &quot;fbodyacc-MEAN-y&quot;                   
## [43] &quot;fbodyacc-MEAN-z&quot;                   
## [44] &quot;fbodyacc-STD-x&quot;                    
## [45] &quot;fbodyacc-STD-y&quot;                    
## [46] &quot;fbodyacc-STD-z&quot;                    
## [47] &quot;fbodyacc-MEANfreq-x&quot;               
## [48] &quot;fbodyacc-MEANfreq-y&quot;               
## [49] &quot;fbodyacc-MEANfreq-z&quot;               
## [50] &quot;fbodyaccjerk-MEAN-x&quot;               
## [51] &quot;fbodyaccjerk-MEAN-y&quot;               
## [52] &quot;fbodyaccjerk-MEAN-z&quot;               
## [53] &quot;fbodyaccjerk-STD-x&quot;                
## [54] &quot;fbodyaccjerk-STD-y&quot;                
## [55] &quot;fbodyaccjerk-STD-z&quot;                
## [56] &quot;fbodyaccjerk-MEANfreq-x&quot;           
## [57] &quot;fbodyaccjerk-MEANfreq-y&quot;           
## [58] &quot;fbodyaccjerk-MEANfreq-z&quot;           
## [59] &quot;fbodygyro-MEAN-x&quot;                  
## [60] &quot;fbodygyro-MEAN-y&quot;                  
## [61] &quot;fbodygyro-MEAN-z&quot;                  
## [62] &quot;fbodygyro-STD-x&quot;                   
## [63] &quot;fbodygyro-STD-y&quot;                   
## [64] &quot;fbodygyro-STD-z&quot;                   
## [65] &quot;fbodygyro-MEANfreq-x&quot;              
## [66] &quot;fbodygyro-MEANfreq-y&quot;              
## [67] &quot;fbodygyro-MEANfreq-z&quot;              
## [68] &quot;fbodyaccmag-MEAN&quot;                  
## [69] &quot;fbodyaccmag-STD&quot;                   
## [70] &quot;fbodyaccmag-MEANfreq&quot;              
## [71] &quot;fbodybodyaccjerkmag-MEAN&quot;          
## [72] &quot;fbodybodyaccjerkmag-STD&quot;           
## [73] &quot;fbodybodyaccjerkmag-MEANfreq&quot;      
## [74] &quot;fbodybodygyromag-MEAN&quot;             
## [75] &quot;fbodybodygyromag-STD&quot;              
## [76] &quot;fbodybodygyromag-MEANfreq&quot;         
## [77] &quot;fbodybodygyrojerkmag-MEAN&quot;         
## [78] &quot;fbodybodygyrojerkmag-STD&quot;          
## [79] &quot;fbodybodygyrojerkmag-MEANfreq&quot;     
## [80] &quot;angletbodyaccMEAN,gravity&quot;         
## [81] &quot;angletbodyaccjerkMEAN,gravityMEAN&quot; 
## [82] &quot;angletbodygyroMEAN,gravityMEAN&quot;    
## [83] &quot;angletbodygyrojerkMEAN,gravityMEAN&quot;
## [84] &quot;anglex,gravityMEAN&quot;                
## [85] &quot;angley,gravityMEAN&quot;                
## [86] &quot;anglez,gravityMEAN&quot;
</code></pre>

<pre><code class="r">## Now that we  have clean column names from the data we can use the data. 
</code></pre>

<p>Now that we have the clean column names we can extract the same columns from our main datasets and bind them. </p>

<pre><code class="r">##Extract the columns which represent the std and mean from the data
X_test_mean_std &lt;- X_test[,mean_std_cols]
X_train_mean_std &lt;- X_train[,mean_std_cols]
##Check the dimensions of the created data frames 
dim(X_test_mean_std)
</code></pre>

<pre><code>## [1] 2947   86
</code></pre>

<pre><code class="r">dim(X_train_mean_std)
</code></pre>

<pre><code>## [1] 7352   86
</code></pre>

<pre><code class="r">##The dimensions of the data_frame are appropriate as we have 86 variables as filtered by us previously
names(Y_train) &lt;- &quot;Activity_Code&quot;
names(Y_test) &lt;- &quot;Activity_Code&quot;
names(subject_test) &lt;- &quot;Subject_Code&quot;
names(subject_train) &lt;- &quot;Subject_Code&quot;
names(X_test_mean_std) &lt;- features_mean_std$V2
names(X_train_mean_std) &lt;- features_mean_std$V2
X_test_mean_std &lt;- tbl_df(cbind(Y_test,cbind(subject_test,X_test_mean_std)))
X_train_mean_std &lt;- tbl_df(cbind(Y_train,cbind(subject_train,X_train_mean_std)))
dim(X_test_mean_std)
</code></pre>

<pre><code>## [1] 2947   88
</code></pre>

<pre><code class="r">dim(X_train_mean_std)
</code></pre>

<pre><code>## [1] 7352   88
</code></pre>

<p>Now we merge the activity_label dataset with our datasets to generate the activity names. To do so we use a left join wherein we keep all the values of left dataset and repeat the corrosponding values in right dataset.</p>

<pre><code class="r">names(activity_label) &lt;- c(&quot;Activity_Code&quot;,&quot;Activity_Name&quot;)
X_test_joined &lt;- tbl_df(merge(X_test_mean_std,activity_label,by.x=&quot;Activity_Code&quot;,by.y=&quot;Activity_Code&quot;,all.X=T))
X_train_joined &lt;- tbl_df(merge(X_train_mean_std,activity_label,by.x=&quot;Activity_Code&quot;,by.y=&quot;Activity_Code&quot;,all.X=T))
## Now we can combine the Training and Test data using rbind function into a single dataframe
X_combined_joined &lt;- as.data.frame(rbind(X_train_joined,X_test_joined))
dim(X_combined_joined)
</code></pre>

<pre><code>## [1] 10299    89
</code></pre>

<pre><code class="r">##We can see the size of the dataframe is same as the final dataframe 86 columns + 3 generated columns and 7352 + 2947 = 10299 rows - which means all the data has been combined.
</code></pre>

<p>Creation of Tidy Data frame. Here we aggregate the data using the Activity_Name and Subject_Code and generate mean for all the other variables.</p>

<pre><code class="r">X_combined_joined$Activity_Name &lt;- as.factor(X_combined_joined$Activity_Name)
X_combined_joined$Subject_Code &lt;- as.factor(X_combined_joined$Subject_Code)
##We need to mean over the observations thus we exclude 3 columns for mean compuation - Activity_Code, Activity_Name and Subject_Code which are respectively 1st,2nd and Last columns of our joined data frame

Tidy_Data_Set &lt;- aggregate(X_combined_joined[,3:(ncol(X_combined_joined)-1)],by=list(Activity_Name = X_combined_joined$Activity_Name,Subject_Code = X_combined_joined$Subject_Code),mean)

dim(Tidy_Data_Set)
</code></pre>

<pre><code>## [1] 180  88
</code></pre>

<pre><code class="r">write.table(Tidy_Data_Set, &quot;tidy.txt&quot;, sep=&quot;\t&quot;)
write.csv(Tidy_Data_Set,&quot;tidy1.csv&quot;,row.names=F)
</code></pre>

<p>Thus we have created a tidy dataset with the mean of all the observations as the final dataframe. This dataframe has been exported in a tab-deliminated text file named Tidy.txt</p>

</body>

</html>
